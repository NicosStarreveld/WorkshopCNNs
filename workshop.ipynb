{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "terNhWKx3o5p"
      },
      "source": [
        "**Πριν ξεκινήσεις να τρέχεις τον κώδικα**\n",
        "\n",
        "Κάνε κλικ στο <kbd>Runtime</kbd> στην κορυφή της σελίδας, και στις επιλογές <kbd>change runtime type</kbd> ή <kbd>runtime options</kbd>. Εκεί επίλεξε ένα κουτάκι που λέει <kbd>(T4) GPU</kbd>.\n",
        "\n",
        "**Πώς χρησιμοποιείς αυτό το αρχείο;**\n",
        "\n",
        "Αυτό το αρχείο είναι ένα *jupyter notebook*, που αποτελείται από κελιά κειμένου (όπως αυτό) και κελιά κώδικα (όπως το παραπάνω). Μπορείς να τρέξεις τα κελιά κώδικα με <kbd>shift</kbd> + <kbd>enter</kbd>. Πριν προχωρήσεις, είναι σημαντικό να τρέξεις το παραπάνω κελί, ώστε o υπολογιστής να μπορεί να εισάγει όλες τις απαραίτητες συναρτήσεις.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bulcPLmR3o5w",
        "outputId": "19fd57c5-56b6-44ac-a738-d31c7378bbc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.24.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.3)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n",
            "Collecting SimpleITK\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.5.3\n",
            "Cloning into 'machine_learning_medical_data_workshop'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Total 116 (delta 0), reused 0 (delta 0), pack-reused 116 (from 1)\u001b[K\n",
            "Receiving objects: 100% (116/116), 29.33 MiB | 27.23 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "import pip\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import torch\n",
        "from PIL import Image\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%pip install medmnist\n",
        "\n",
        "%pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "!git clone https://github.com/clarastegehuis/machine_learning_medical_data_workshop/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw1B-Xv03o5z"
      },
      "source": [
        "# Τα μαθηματικά πίσω από την ΤΝ - Εφαρμογή: ιατρικά δεδομένα\n",
        "\n",
        "Τα νευρωνικά δίκτυα (CNNs) μπορούν να χρησιμοποιηθούν για την αυτόματη ερμηνεία εικόνων. Οι υπολογιστές είναι μάλιστα καλύτεροι σε ορισμένες εργασίες ανάλυσης εικόνας από τους ανθρώπους, επειδή οι άνθρωποι έχουν μικρή διάρκεια συγκέντρωσης. Σ' αυτό το εργαστήριο θα ρίξουμε μια ματιά στο πώς ένας υπολογιστής μπορεί να ερμηνεύει εικόνες. Θα εργαστούμε με ένα (δημόσιο) ιατρικό σύνολο δεδομένων και θα εκπαιδεύσουμε το δικό μας δίκτυο που μπορεί να ξεχωρίζει μεταξύ εικόνων δοντιών με και χωρίς απονεύρωση."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "a4SfsRUu3o5z"
      },
      "source": [
        "### Ψηφιακές εικόνες\n",
        "\n",
        "Ο υπολογιστής βλέπει μια εικόνα ως έναν μεγάλη πίνακα με αριθμούς, κάθε στοιχείο του πίνακα (γνωστότερο ως *pixel*) περιέχει την τοπική ένταση της εικόνας. Στην περίπτωση μιας έγχρωμης εικόνας, πρόκειται για τρεις πίνακες τον έναν πάνω στον άλλο, που αντιπροσωπεύουν αντίστοιχα το κόκκινο, το μπλε και το πράσινο κανάλι. Στην περίπτωση μιας ασπρόμαυρης εικόνας, η ψηφιακή εικόνα είναι ένας μοναδικός πίνακας με εντάσεις."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CI1JKPCg3o50"
      },
      "outputs": [],
      "source": [
        "#definieert twee functies die je later kan gebruiken om de images te openen en te visualiseren\n",
        "def open_img(path):\n",
        "    if path.endswith('.png'):\n",
        "        return np.array(Image.open(path).convert('L'))\n",
        "    elif path.endswith('.mhd'):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(path))[32,:,:] # return 1 slice of the image\n",
        "\n",
        "def visualize(img, clim=[-300,450]):\n",
        "    plt.imshow(img, cmap='gray', clim=clim)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W0Pdttg3o51"
      },
      "outputs": [],
      "source": [
        "# inladen van beeld van de ribbenkast\n",
        "# definieer pad naar beeld\n",
        "# img_path = 'data/ribs/VinDr_RibCXR_train_000.png'\n",
        "img_path = '/content/machine_learning_medical_data_workshop/TEV1P1CTI.mhd'\n",
        "img = open_img(img_path)\n",
        "# visualiseer beeld\n",
        "visualize(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6DGpqZq3o51"
      },
      "source": [
        "Uit hoeveel pixels bestaat dit beeld? np.shape(img) laat de vorm (aantal rijen en kolommen) van de matrix zien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0NNObc83o52"
      },
      "outputs": [],
      "source": [
        "print(np.shape(img))\n",
        "\n",
        "# Hoe veel pixels zijn dit?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoS-8q793o52"
      },
      "source": [
        "### Convoluties\n",
        "Een computer kan een beeld begrijpen door middel van zogenaamde convoluties. Een convolutie bestaat altijd uit een *kernel*, een kleine matrix met daarin een kenmerkend patroon, die lokaal wordt vermenigvuldigd met de beeldintensiteiten. In de onderstaande animatie is het bovenste groene vlak de kernel, en het blauwe vlak het te interpreteren beeld, het schuiven van de kernel noemen we de convolutie. Het resultaat van een convolutie is nog steeds een *matrix*, die vergelijkbare afmetingen heeft als het originele beeld.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif?20190413174630)\n",
        "\n",
        " Met een convolutie wordt in feite de intensiteit van iedere pixel vergeleken met die van zijn buren, afhankelijk van het patroon in de kernel. Door het patroon in de kernel slim te kiezen, kunnen bepaalde features in het beeld worden opgepikt, bijvoorbeeld verticale randen. Effectief wordt er per pixel gekeken hoe zijn omgeving matcht met het patroon in de kernel. Daarnaast kan een convolutie gebruikt worden om ruis in een beeld te verminderen, dit noemen we *smoothing*.\n",
        "\n",
        " Hieronder laten we een paar voorbeelden van convolutiekernels zien, aan jullie om te beschrijven wat voor effect ze hebben op het beeld."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTXICX-R3o52"
      },
      "outputs": [],
      "source": [
        "# dit is een functie die een convolution toepast op een beeld\n",
        "def apply_conv(image, kernel, iter=1):\n",
        "    image, kernel = torch.from_numpy(image).float(), torch.from_numpy(kernel).float()\n",
        "    img_shape, kernel_shape = image.shape, kernel.shape\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    for level in range(iter):\n",
        "        image = F.conv2d(image.reshape(1,1, img_shape[0], img_shape[1]),\n",
        "                         kernel.reshape(1,1, kernel_shape[0], kernel_shape[1]),\n",
        "                         padding='same').squeeze()\n",
        "        ax.imshow(image.numpy(), cmap='gray', clim=[-300,450])\n",
        "        ax.set_title(f'Applied convolution {level+1} times')\n",
        "        display(fig)\n",
        "        clear_output(wait=True)\n",
        "        plt.pause(0.1)\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2A9CkSr3o53"
      },
      "source": [
        "Nu kun je zelf een kernel loslaten op het beeld van de ribben.\n",
        "\n",
        "**Vraag:**\n",
        "Wat gebeurt er met het beeld door de convolutie? En wat gebeurt er als je meerdere convoluties achter elkaar toepast?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTpniJke3o53"
      },
      "outputs": [],
      "source": [
        "# convolutie 1: detecteren verschuiven naar links\n",
        "# eerst kernel definieren:\n",
        "kernel = np.array([[0, 0, 0],\n",
        "                   [0, 0, 1],\n",
        "                   [0, 0, 0]])\n",
        "# hoe vaak willen we de convolutie toepassen?\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_7ns18h3o53"
      },
      "source": [
        "De tweede convolutie veschuift het beeld naar boven.\n",
        "\n",
        "**Vraag:** Kun je ook een convolutie maken die het beeld naar rechts beneden schuift (schuin)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld171WUr3o54"
      },
      "outputs": [],
      "source": [
        "# convolutie 2: verschuiven naar boven\n",
        "# eerst kernel definieren:\n",
        "kernel = np.array([[0, 0, 0],\n",
        "                   [0, 0, 0],\n",
        "                   [0, 1, 0]])\n",
        "# hoe vaak willen we de convolutie toepassen?\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zYKF-MH3o54"
      },
      "source": [
        "Als het goed is heb je hierboven begrepen hoe je een beeld naar rechts, links, boven of onder kan verplaatsen, of schuin kan verplaatsen. Als je de kernel groter maakt, kun je je beeld ook ingewikkeldere sprongen laten maken.\n",
        "\n",
        "**Vraag:**\n",
        "Kun je bijvoorbeeld met een $5 \\times 5$ kernel het beeld een paardensprong laten maken? (2 pixels omhoog, en 1 naar links)? Nu staan er alleen maar nullen in de kernel, dus je moet 1 of meerdere vakjes aanpassen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOZaFoZw3o54"
      },
      "outputs": [],
      "source": [
        "# Opdracht: maak een convolutie die het beeld een paardensprong laat maken: i\n",
        "kernel = np.array([[0, 0, 0, 0, 0],\n",
        "                   [0, 0, 0, 0, 0],\n",
        "                   [0, 0, 0, 0, 0],\n",
        "                   [0, 0, 0, 0, 0],\n",
        "                   [0, 0, 0, 0, 0]])\n",
        "\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnJcB6-g3o54"
      },
      "source": [
        "De convolutie hieronder past 'smoothing' toe, en maakt het beeld onscherper.\n",
        "\n",
        "**Vraag:** Wat gebeurt er als je de gewichten in de kernel iets aanpast?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEu3oLsM3o54"
      },
      "outputs": [],
      "source": [
        "# convolutie 3: Een convolutie die 'smoothing' toepast: Voor iedere pixel neemt de convolution het gewogen gemiddelde van de pixelwaarde en de pixelwaarden van de 8 omliggende pixels. Wat gebeurt er als je de gewichten van de kernel aanpast?\n",
        "kernel = np.array([[1, 2, 1],\n",
        "                   [2, 4, 2],\n",
        "                   [1, 2, 1]]) * 1/16\n",
        "\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWVVq2qF3o54"
      },
      "source": [
        "De onderstaande convolutie hadden we eerder al gezien, die vindt verticale lijnen. Deze convolutie hoef je maar één keer toe te passen, omdat je in een keer alle lijnen kunt vinden.\n",
        "\n",
        "**Vraag:** Kun je ook een convolutie maken die horizontale lijnen vindt? En wat gebeurt er als je de 1 en en -1 en omdraait?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhKlinC03o55"
      },
      "outputs": [],
      "source": [
        "# convolutie 3: detecteren van verticale lijnen\n",
        "kernel = np.array([[1, 0, -1],\n",
        "                   [1, 0, -1],\n",
        "                   [1, 0, -1]])\n",
        "\n",
        "n_iters = 1\n",
        "\n",
        "apply_conv(img, kernel, n_iters)\n",
        "\n",
        "\n",
        "# opdracht:kun je ook een kernel maken die horizontale randen vindt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7J6sNJV3o55"
      },
      "source": [
        "## Convolutional Neural Network\n",
        "Deze convolutieoperaties vormen de basis van een zogenaamd *convolutional neural network*. In principe is dit een neuraal netwerk dat kan worden ingezet voor allerlei computer vision taken, zoals het classificeren van beelden, objecten detecteren of zelfs de precieze grenzen van een object vinden in een beeld. Convolutional neural networks bestaan uit een stapeling van convoluties. Door convoluties vaker toe te passen in een 'stapel', kan de computer een groeiende lokale regio rondom elke pixel kan bekijken (perceptive field).\n",
        "De kernels in al deze convoluties worden niet door mensen bepaald, maar worden bepaald tijdens het *trainen* van dit netwerk. In de rest van dit notebook laten we een klein voorbeeld zien van hoe dit werkt en hoe we kunnen bepalen hoe goed dit netwerk is in zijn taak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyXrBC-r3o55"
      },
      "source": [
        "**De taak:**\n",
        "\n",
        "We maken gebruik van de zogenaamde pneumonia dataset. Deze bevat gedownsamplede röntgenfoto's van de borstkas, van zowel gezonde patienten als van patienten met een longontsteking. We gaan een neuraal netwerk trainen dat automatisch voor een dergelijk beeld kan bepalen of er sprake is van longontsteking of niet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-XV4MvG3o55"
      },
      "outputs": [],
      "source": [
        "# downoald de dataset met foto's van de longen\n",
        "import medmnist\n",
        "%pip install monai\n",
        "\n",
        "dataset = medmnist.PneumoniaMNIST(split=\"train\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73Bwv5B3o55"
      },
      "outputs": [],
      "source": [
        "import monai\n",
        "# maakt een custom dataset class die de data in de juiste vorm geeft\n",
        "\n",
        "class MedMNISTData(monai.data.Dataset):\n",
        "\n",
        "    def __init__(self, datafile, transform=None):\n",
        "        self.data = datafile\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Make getitem return a dictionary with keys ['img', 'label'] for the image and label respectively\n",
        "        image = torch.from_numpy(np.array(self.data[index][0])).float()\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {'img': image, 'label': self.data[index][1]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5OPaqJb3o55"
      },
      "outputs": [],
      "source": [
        "# Een functie die de foto's uit de dataset visualiseert\n",
        "def visualize_sample(sample):\n",
        "    plt.imshow(sample['img'], 'gray')\n",
        "    if sample['label'] == 1:\n",
        "        plt.title('Patient with pneumonia')\n",
        "    else:\n",
        "        plt.title('Healthy patient')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCukq9NA3o56"
      },
      "outputs": [],
      "source": [
        "# Intensiteiten normaliseren voor het netwerk straks en de training data maken\n",
        "from monai.transforms import NormalizeIntensity\n",
        "\n",
        "data_transform = NormalizeIntensity(subtrahend=.5, divisor=.5)\n",
        "\n",
        "train_dataset = MedMNISTData(dataset, transform=data_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYes0xWe3o56"
      },
      "source": [
        "### Vraag 1 (doel: experimenteren met code en dataset verkennen):\n",
        "train_dataset is een verzameling van 4708 scans waarin elke scan een label heeft, deze kan 0 of 1 zijn. Label 0 betekent dat de patient gezond is, en label 1 betekent dat de patient longontsteking heeft , Als je <kbd>visualize(train_dataset[k][‘img’])</kbd> intoetst dan kun je het $k$-de plaatje zien, en als je <kbd>print(train_dataset[k][‘label’])</kbd> intoetst dan zie je de label die bij dat plaatje hoort. Experimenteer met <kbd>visualize_sample(train_dataset[k])</kbd> om de dataset te verkennen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRckFklx3o56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO7ro6ug3o56"
      },
      "source": [
        "Hieronder kun je een foto de longen van een willekeurige patient laten zien. Om de voorspellingen van het algoritme later beter te kunnen interpreteren, is het belangrijk om te weten hoe veel foto's er in de data zitten van gezonde longen, en hoe veel er van ongezonde longen inzitten.\n",
        "\n",
        "Hieronder kun je kijken hoe veel data uit de ene, en uit de andere klasse komen.\n",
        "\n",
        "**Vraag:** Is de dataset gebelanceerd? Hoe veel procent van de trainingsdata gaat over patienten met een longontsteking?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEtLMVvw3o56"
      },
      "outputs": [],
      "source": [
        "# visualiseer een random sample\n",
        "index = np.random.choice(np.arange(len(train_dataset)))\n",
        "visualize_sample(train_dataset[index])\n",
        "\n",
        "#Vraag: is deze dataset imbalanced?\n",
        "counts = {0: 0, 1:0}\n",
        "for sample in train_dataset:\n",
        "    counts[sample['label'][0]] += 1\n",
        "print('Aanal label 0:', counts[0], 'Aantal label 1:', counts[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFKpnIj3o56"
      },
      "source": [
        "Nu gaan we het echte netwerk aanmaken. We splitsen de data in een testset en een validatieset om later te kunnen kijken of het model niet overfit. We maken een model met twee lagen van convoluties van 3x3 kernels. Daarachter komt een neuraal netwerk, en we zorgen dat er één output is (wel of niet longontsteking). Dit model staat geprogrammeerd als Net().\n",
        "\n",
        "\n",
        "**Vraag:**\n",
        "Wat is de receptive field van dit netwerk (hoe veel pixels)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpjW25113o56"
      },
      "outputs": [],
      "source": [
        "# validatiedataset aanmaken, om te kijken hoe het model generaliseert tijdens het trainen. De validatieset wordt niet gebruikt om de gewichten van het model op te fitten.\n",
        "val_dataset = MedMNISTData(medmnist.PneumoniaMNIST(split='val', download=False))\n",
        "\n",
        "# dataloader die de data inlaadt voor het trainen\n",
        "train_dataloader = monai.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = monai.data.DataLoader(val_dataset, batch_size = 32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bLlSVbH3o57"
      },
      "outputs": [],
      "source": [
        "# Hier wordt het echte model gedefinieerd. Dit model is een convolutioneel neuraal netwerk (CNN) dat bestaat uit 2 convolutionele lagen en 2 fully connected lagen.\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)             # Een convolutie met 1 input channel (de afbeelding), 32 output channels (32 verschillende kernels), 3x3 pixel kernel\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)            # Een tweede convolutie met 32 input channels (de 32 output channels van de vorige laag), 64 output channels (verschillende kernels), 3x3 pixel kernel\n",
        "        self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=1)                                       # De output laag met 1 output neuron (de voorspelling, tussen 0 (geen longontsteking) en 1( longontsteking) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        output = self.fc2(x)\n",
        "        return output\n",
        "\n",
        "net = Net()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVBatyT3o57"
      },
      "source": [
        "We moeten ook bepalen wat de loss functie is die het netwerk gebruikt als we gaan trainen. We gebruiken de 'binary cross-entropy loss' die we besproken hadden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLuyJ6x_3o57"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "model.cuda() # op de GPU zetten, zodat het trainen sneller gaat\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "# loss functie: Binary cross entropy (want classificatie).\n",
        "loss_function = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF9XCG_E3o57"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# functie om het model te trainen\n",
        "\n",
        "def train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs, device='cuda', val_freq=1):\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # model in train modus\n",
        "        model.train()\n",
        "        steps = 0\n",
        "        epoch_loss = 0\n",
        "        # loop over de batches in training data\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            images = batch['img'].float().to(device)\n",
        "            labels = batch['label'].float().to(device)\n",
        "            # haal plaatjes door het model\n",
        "            output = model(images.unsqueeze(1))\n",
        "            # bereken de loss tussen de targets en de outputs van het model\n",
        "            loss = loss_function(output, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            # back propagation, update de weights in het netwerk\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            steps += 1\n",
        "\n",
        "        train_loss.append(epoch_loss/steps)\n",
        "\n",
        "        # validation loop\n",
        "        if epoch % val_freq == 0:\n",
        "            steps = 0\n",
        "            val_epoch_loss = 0\n",
        "            model.eval()\n",
        "            for batch in val_dataloader:\n",
        "                images = batch['img'].float().to(device)\n",
        "                labels = batch['label'].float().to(device)\n",
        "                output = model(images.unsqueeze(1))\n",
        "                loss = loss_function(output, labels)\n",
        "                val_epoch_loss += loss.item()\n",
        "                steps += 1\n",
        "            val_loss.append(val_epoch_loss/steps)\n",
        "\n",
        "    # plot the losses together\n",
        "    plt.plot(train_loss, label='train loss')\n",
        "    plt.plot(np.arange(0, epochs, val_freq), val_loss, label='val loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model, train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN5RUEDz3o57"
      },
      "source": [
        "Nu we het neurale netwerk, de loss functie, de data geïntroduceerd is, kunnen we het model echt gaan trainen, en de kernels leren die het model gaat gebruiken om gezonde en ongezonde patiënten te onderscheiden. De code hieronder laat zien hoe de loss functie naar beneden gaat tijdens de training, op zowel te trainingsdata als de validatiedata.\n",
        "\n",
        "\n",
        "**Vraag:** Als je de plots van de loss functie op de trainingsdata en op de validatiedata ziet, is het model dan overfitted denk je? En nu hebben we het model 100 epochs getraind. Had dit ook korter gekund?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LImMggkT3o57"
      },
      "outputs": [],
      "source": [
        "val_freq = 10\n",
        "\n",
        "# 100 iteraties trainen\n",
        "n_epochs = 100\n",
        "model, train_loss, val_loss = train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs=n_epochs, val_freq=val_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSsxx5gV3o58"
      },
      "source": [
        "We hebben hierboven gezien wat specifieke kernels kunnen herkennen in een beeld. Maar wat heeft ons algoritme voor kernels gevonden om te classificeren tussen gezonde en zieke longen? Hieronder zien we de kernels van de tweede laag van convoluties. Omdat de eerste laag al 16 convoluties heeft gedaan, zijn er 16 verschillende lagen van kernels in de tweede laag. Je kunt ze allemaal bekijken door de variabele <kbd>input_index</kbd> aan te passen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqUrH8nI3o6Q"
      },
      "outputs": [],
      "source": [
        "input_index = 16\n",
        "fig, axs = plt.subplots(8,8, layout='constrained')\n",
        "for i in range(64):\n",
        "    kernel = model.conv2.weight[i,input_index,:,:].detach().cpu().numpy()\n",
        "    cur_ax = np.unravel_index(i, [8,8])\n",
        "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
        "    axs[cur_ax].axis('off')\n",
        "plt.suptitle(f'Geleerde kernels uit de tweede convolutional laag, input channel {input_index}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDDykKEZ3o6Q"
      },
      "source": [
        "En hier zien we ook de kernels uit de eerste laag van convoluties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_3dOIFB3o6R"
      },
      "outputs": [],
      "source": [
        "print(np.shape(model.conv1.weight))\n",
        "fig, axs = plt.subplots(4,8, layout='constrained')\n",
        "for i in range(32):\n",
        "    kernel = model.conv1.weight[i,0,:,:].detach().cpu().numpy()\n",
        "    cur_ax = np.unravel_index(i, [4,8])\n",
        "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
        "    axs[cur_ax].axis('off')\n",
        "plt.suptitle(f'Geleerde kernels uit de eerste convolutional laag')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUUfgnJF3o6R"
      },
      "source": [
        "## Performance assessment\n",
        "\n",
        "Nu we het model getraind hebben, gaan we kijken in hoeverre dit model goede voorspellingen kan doen. Eerst bepalen we de recall en precision van het model. De recall vertelt ons hoeveel van de positieven er gemist worden door het model (vals negatieven). De precisie meet hoeveel van de positief geclassificeerde samples daadwerkelijk positieve samples zijn (vals positieven). Welke maat belangrijker is, is afhankelijk van het probleem. Bij het detecteren van een extreem zeldzame vorm van kanker heb je bijvoorbeeld het liefst een hoge recall en accepteer je daarmee een lagere precisie. Het is beter om de daadwerkelijke positieven wél te detecteren en daarmee in een vervolgonderzoek de vals positieven eruit te filteren, dan de positieven compleet te missen.\n",
        "We gebruiken de test dataset (dus niet de validatiedataset) om deze metrics te bepalen.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)\n",
        "\n",
        "Voordat we deze metrics gaan bepalen, bekijken we eerst een paar outputs van het model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddpeEeNZ3o6R"
      },
      "outputs": [],
      "source": [
        "def validation_results_visualize(model, dataset):\n",
        "    index = np.random.randint(0, len(dataset))\n",
        "    image = dataset[index]['img']\n",
        "    plt.imshow(image.numpy().squeeze(), cmap='gray')\n",
        "    image = image.float().to('cuda')\n",
        "    label = dataset[index]['label'].item()\n",
        "    with torch.no_grad():\n",
        "        output = F.sigmoid(model(image.view(1,1,28,28))).squeeze()\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    plt.title(f'Echte waarde: {label}, voorspelling model: {int(output)}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PvUsCFH3o6R"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    validation_results_visualize(model, val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTISi7aE3o6R"
      },
      "outputs": [],
      "source": [
        "# deze functien berekent de precision en recall van het model\n",
        "def get_precision_recall(model, dataloader):\n",
        "    model.eval()\n",
        "    TP, TN, FP, FN = 0, 0, 0, 0\n",
        "    total = 0\n",
        "    for data in dataloader:\n",
        "        images = data['img'].float().to('cuda')\n",
        "        labels = data['label'].squeeze()\n",
        "        total += len(labels)\n",
        "        with torch.no_grad():\n",
        "            output = F.sigmoid(model(images.unsqueeze(1))).squeeze().cpu()\n",
        "        pred_classes = (output >= 0.5).to(torch.int8)\n",
        "        TP += (pred_classes * labels).sum()\n",
        "        TN += ((1 - pred_classes) * (1 - labels)).sum()\n",
        "        FP += (pred_classes * (1 - labels)).sum()\n",
        "        FN += ((1 - pred_classes) * labels).sum()\n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    return precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDuhQylk3o6R"
      },
      "outputs": [],
      "source": [
        "test_dataset = MedMNISTData(medmnist.PneumoniaMNIST(split='test', download=False))\n",
        "test_loader = monai.data.DataLoader(test_dataset, batch_size = 32, shuffle=False)\n",
        "\n",
        "precision, recall = get_precision_recall(model, test_loader)\n",
        "print(f'De precision van het getrainde model is {precision:.2f}, de recall van het getrainde model is {recall:.2f}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgCnyfTk3o6S"
      },
      "source": [
        "**Vraag:** Wat vind je van de precisie en recall van het model (ook denkend aan hoe veel procent van de patienten in de data longontsteking hebben?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO7AxRs93o6S"
      },
      "source": [
        "Hieronder kun je een zogenaamde 'confusion matrix' zien. Hoe veel longontstekingen zijn over het hoofd gezien? En hoe vaak wordt er een patient onterecht gediagnostiseerd met longontsteking? Welk beeld geeft dit van hoe krachtig het model is? Kun je er ook achterkomen of het model ook goed werkt op de validatiedataset? De dataloader voor de validatieset heet <kbd>val_dataloader</kbd>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9fd8YXu3o6S"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model,dataloader):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using true and predicted labels.\n",
        "\n",
        "    :param y_true: List or array of true labels.\n",
        "    :param y_pred: List or array of predicted labels.\n",
        "    :param labels: List of label names (optional).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "\n",
        "    for data in dataloader:\n",
        "        images = data['img'].float().to('cuda')\n",
        "        labels = data['label'].squeeze()\n",
        "        with torch.no_grad():\n",
        "            output = F.sigmoid(model(images.unsqueeze(1))).squeeze().cpu()\n",
        "        pred_classes = (output >= 0.5).to(torch.int8)\n",
        "        true_labels.extend(labels.numpy())\n",
        "        predicted_labels.extend(pred_classes.numpy())\n",
        "\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=[0,1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['geen longontsteking', 'longontsteking'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}