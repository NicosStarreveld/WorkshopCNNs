{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "terNhWKx3o5p"
      },
      "source": [
        "**Πριν ξεκινήσεις να τρέχεις τον κώδικα**\n",
        "\n",
        "Κάνε κλικ στο <kbd>Runtime</kbd> στην κορυφή της σελίδας, και στις επιλογές <kbd>change runtime type</kbd> ή <kbd>runtime options</kbd>. Εκεί επίλεξε ένα κουτάκι που λέει <kbd>(T4) GPU</kbd>.\n",
        "\n",
        "**Πώς χρησιμοποιείς αυτό το αρχείο;**\n",
        "\n",
        "Αυτό το αρχείο είναι ένα *jupyter notebook*, που αποτελείται από κελιά κειμένου (όπως αυτό) και κελιά κώδικα (όπως το παραπάνω). Μπορείς να τρέξεις τα κελιά κώδικα με <kbd>shift</kbd> + <kbd>enter</kbd>. Πριν προχωρήσεις, είναι σημαντικό να τρέξεις το παραπάνω κελί, ώστε o υπολογιστής να μπορεί να εισάγει όλες τις απαραίτητες συναρτήσεις.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bulcPLmR3o5w"
      },
      "outputs": [],
      "source": [
        "#Ενότητα 1: Εισαγωγή απραίτητων εργαλείων\n",
        "\n",
        "import pip\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import torch\n",
        "from PIL import Image\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%pip install medmnist\n",
        "\n",
        "%pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "!git clone https://github.com/NicosStarreveld/WorkshopCNNs.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw1B-Xv03o5z"
      },
      "source": [
        "# Τα μαθηματικά πίσω από την ΤΝ - Εφαρμογή: ιατρικά δεδομένα\n",
        "\n",
        "Τα νευρωνικά δίκτυα (CNNs) μπορούν να χρησιμοποιηθούν για την αυτόματη ερμηνεία εικόνων. Οι υπολογιστές είναι μάλιστα καλύτεροι σε ορισμένες εργασίες ανάλυσης εικόνας από τους ανθρώπους, επειδή οι άνθρωποι έχουν μικρή διάρκεια συγκέντρωσης. Σ' αυτό το εργαστήριο θα ρίξουμε μια ματιά στο πώς ένας υπολογιστής μπορεί να ερμηνεύει εικόνες. Θα εργαστούμε με ένα (δημόσιο) ιατρικό σύνολο δεδομένων και θα εκπαιδεύσουμε το δικό μας δίκτυο που μπορεί να ξεχωρίζει μεταξύ εικόνων δοντιών με και χωρίς απονεύρωση."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "a4SfsRUu3o5z"
      },
      "source": [
        "### Ψηφιακές εικόνες\n",
        "\n",
        "Ο υπολογιστής βλέπει μια εικόνα ως έναν μεγάλη πίνακα με αριθμούς, κάθε στοιχείο του πίνακα (γνωστότερο ως *pixel*) περιέχει την τοπική ένταση της εικόνας. Στην περίπτωση μιας έγχρωμης εικόνας, πρόκειται για τρεις πίνακες τον έναν πάνω στον άλλο, που αντιπροσωπεύουν αντίστοιχα το κόκκινο, το μπλε και το πράσινο κανάλι. Στην περίπτωση μιας ασπρόμαυρης εικόνας, η ψηφιακή εικόνα είναι ένας μοναδικός πίνακας με εντάσεις."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI1JKPCg3o50"
      },
      "outputs": [],
      "source": [
        "#Ενότητα 2: προβολή εικόνων\n",
        "\n",
        "def open_img(path):\n",
        "    if path.endswith('.png'):\n",
        "        return np.array(Image.open(path).convert('L'))\n",
        "    elif path.endswith('.mhd'):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(path))[32,:,:] # return 1 slice of the image\n",
        "\n",
        "def visualize(img, clim=[-300,450]):\n",
        "    plt.imshow(img, cmap='gray', clim=clim)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Για να διαβάσει σωστά τις εικόνες πρέπει να δώσουμε τη διεύθυνση στην οποία\n",
        "είναι καταχωρημένες. Οι φωτογραφίες είναι σε δύο φακέλους Xrays_with & Xrays_without\n",
        "\"\"\"\n",
        "\n",
        "img_path = 'WorkshopCNNs/Xrays_with/167.png'\n",
        "img = open_img(img_path)\n",
        "# visualiseer beeld\n",
        "visualize(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoS-8q793o52"
      },
      "source": [
        "### Convolutions\n",
        "\n",
        "Ένας υπολογιστής μπορεί να κατανοήσει μια εικόνα μέσω των λεγόμενων convolutions (συνέληξεις). Ένα convolution αποτελείται πάντα από έναν *πυρήνα* (kernel), έναν μικρό πίνακα που περιέχει ένα χαρακτηριστικό μοτίβο, το οποίο πολλαπλασιάζεται τοπικά με τις εντάσεις της εικόνας. Στην παρακάτω κινούμενη εικόνα, το ανώτερο πράσινο επίπεδο είναι ο πυρήνας, και το μπλε επίπεδο είναι η εικόνα που πρέπει να ερμηνευτεί, η μετακίνηση του πυρήνα ονομάζεται convolution. Το αποτέλεσμα ενός convolution είναι ακόμα ένας *πίνακας*, ο οποίος έχει παρόμοιες διαστάσεις με την αρχική εικόνα.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif?20190413174630)\n",
        "\n",
        " Με μια συνελικτική λειτουργία στην ουσία συγκρίνεται η ένταση κάθε pixel με αυτή των γειτόνων του, ανάλογα με το μοτίβο στον πυρήνα. Επιλέγοντας έξυπνα το μοτίβο στον πυρήνα, μπορούν να αναγνωριστούν ορισμένα χαρακτηριστικά στην εικόνα, για παράδειγμα οι κάθετες άκρες. Αποτελεσματικά, για κάθε pixel εξετάζεται πώς το περιβάλλον του ταιριάζει με το μοτίβο στον πυρήνα. Επιπλέον, μια συνελικτική λειτουργία μπορεί να χρησιμοποιηθεί για τη μείωση του θορύβου σε μια εικόνα, κάτι που ονομάζεται *smoothing*.\n",
        "\n",
        "Παρακάτω παρουσιάζουμε μερικά παραδείγματα συνελικτικών πυρήνων/ Αυτά τα παραδείγματα δεν έχουν σχέση με την εφαρμογή που θέλουμε, τα δίνω απλά για να δείξω τι κάνει ένας πυρήνας όταν εφαρμοστεί πάνω σε μια εικόνα."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTXICX-R3o52"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 3: Μια συνάρτηση η οποία εφαρμόζει έναν πυρήνα kernel πάνω σε μια εικόνα image.\n",
        "\n",
        "def apply_conv(image, kernel, iter=1):\n",
        "    image, kernel = torch.from_numpy(image).float(), torch.from_numpy(kernel).float()\n",
        "    img_shape, kernel_shape = image.shape, kernel.shape\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    for level in range(iter):\n",
        "        image = F.conv2d(image.reshape(1,1, img_shape[0], img_shape[1]),\n",
        "                         kernel.reshape(1,1, kernel_shape[0], kernel_shape[1]),\n",
        "                         padding='same').squeeze()\n",
        "        ax.imshow(image.numpy(), cmap='gray', clim=[-300,450])\n",
        "        ax.set_title(f'Applied convolution {level+1} times')\n",
        "        display(fig)\n",
        "        clear_output(wait=True)\n",
        "        plt.pause(0.1)\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTpniJke3o53"
      },
      "outputs": [],
      "source": [
        "# convolutiοn 1: move image to the left\n",
        "# define kernel:\n",
        "kernel = np.array([[0, 0, 0],\n",
        "                   [0, 0, 1],\n",
        "                   [0, 0, 0]])\n",
        "# how often we apply the kernel\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEu3oLsM3o54"
      },
      "outputs": [],
      "source": [
        "# convolution 2: smoothing\n",
        "kernel = np.array([[1, 2, 1],\n",
        "                   [2, 4, 2],\n",
        "                   [1, 2, 1]]) * 1/16\n",
        "\n",
        "n_iters = 20\n",
        "\n",
        "apply_conv(img, kernel, n_iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhKlinC03o55"
      },
      "outputs": [],
      "source": [
        "# convolution 3: detecting vertical lines\n",
        "kernel = np.array([[1, 0, -1],\n",
        "                   [1, 0, -1],\n",
        "                   [1, 0, -1]])\n",
        "\n",
        "n_iters = 1\n",
        "\n",
        "apply_conv(img, kernel, n_iters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7J6sNJV3o55"
      },
      "source": [
        "## Convolutional Neural Network\n",
        "\n",
        "Οι εν λόγω συνελικτικές λειτουργίες αποτελούν τη βάση ενός λεγόμενου συνελικτικού νευρωνικού δικτύου. Στην ουσία, πρόκειται για ένα νευρωνικό δίκτυο που μπορεί να χρησιμοποιηθεί για διάφορες εργασίες υπολογιστικής όρασης, όπως η ταξινόμηση εικόνων, η ανίχνευση αντικειμένων ή ακόμη και ο προσδιορισμός των ακριβών ορίων ενός αντικειμένου σε μια εικόνα. Τα συνελικτικά νευρωνικά δίκτυα αποτελούνται από μια στοίβα συνελικτικών επιπέδων. Εφαρμόζοντας συνεχώς συνελικτικές λειτουργίες μέσα σε μια «στοίβα», ο υπολογιστής μπορεί να εξετάζει μια ολοένα και μεγαλύτερη τοπική περιοχή γύρω από κάθε εικονοστοιχείο (perceptive field). Οι πυρήνες σε όλες αυτές τις συνελικές λειτουργίες δεν καθορίζονται από ανθρώπους, αλλά προσδιορίζονται κατά τη διάρκεια της εκπαίδευσης αυτού του δικτύου. Στην υπόλοιπη ενότητα αυτού του notebook θα δείξουμε ένα μικρό παράδειγμα του πώς λειτουργεί αυτό και πώς μπορούμε να αξιολογήσουμε πόσο καλό είναι το δίκτυο στη συγκεκριμένη εργασία του."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Σωστή βάση δεδομένων σύμφωνα με τις οδηγίες του ΜedMNist"
      ],
      "metadata": {
        "id": "Y-H1H08zcaf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ενότητα 4: Φτιάχνω τις εικόνες που έφτιαξες σε μορφή ώστε να τις διαβάσει το CNN\n",
        "\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "originals = []\n",
        "\n",
        "for filename in os.listdir(\"WorkshopCNNs/Xrays_with\"):\n",
        "  if 'ipynb' in filename: continue\n",
        "  orig_img = cv2.imread(f\"WorkshopCNNs/Xrays_with/{filename}\", cv2.IMREAD_GRAYSCALE)\n",
        "  img = cv2.resize(orig_img, (28, 28))\n",
        "  img = img.astype(np.uint8)\n",
        "  images.append(img)\n",
        "  labels.append([1])\n",
        "  originals.append(orig_img)\n",
        "\n",
        "for filename in os.listdir(\"WorkshopCNNs/Xrays_without\"):\n",
        "  if 'ipynb' in filename: continue\n",
        "  img = cv2.imread(f\"WorkshopCNNs/Xrays_without/{filename}\", cv2.IMREAD_GRAYSCALE)\n",
        "  img = cv2.resize(orig_img, (28, 28))\n",
        "  img = img.astype(np.uint8)\n",
        "  images.append(img)\n",
        "  labels.append([0])\n",
        "  originals.append(orig_img)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "originals = np.array(originals, dtype=object)"
      ],
      "metadata": {
        "id": "634bLW8F7uIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val/test splits\n",
        "X_train, X_temp, X_train_orig, X_temp_orig, y_train, y_temp = train_test_split(images, originals, labels, test_size=0.3)\n",
        "X_val, X_test, X_val_orig, X_test_orig, y_val, y_test = train_test_split(X_temp, X_temp_orig, y_temp, test_size=0.5)"
      ],
      "metadata": {
        "id": "aP1KyZ2v8XGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opslaan in MedMNIST-formaat\n",
        "np.savez(\"teethmnist.npz\",\n",
        "         train_images=X_train, train_labels=y_train, train_orig=X_train_orig,\n",
        "         val_images=X_val, val_labels=y_val, val_orig = X_val_orig,\n",
        "         test_images=X_test, test_labels=y_test, test_orig = X_test_orig)"
      ],
      "metadata": {
        "id": "ceE1afUv8YFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στον κώδικα εδώ κάτω φτιάχνω μια βάση δεδομένων (κλάση) TeethMNIST με τα σωστά labels. Το CNN θα χρησιμοποιήσει αυτήν την κλάση."
      ],
      "metadata": {
        "id": "hCokznbpco7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ενότητα 5: Κλάση TeethMNIST\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TeethMNIST(Dataset):\n",
        "  def __init__(self, split=\"train\", transform=None):\n",
        "      data = np.load(\"teethmnist.npz\", allow_pickle=True)\n",
        "\n",
        "      self.images = data[f\"{split}_images\"]\n",
        "      self.labels = data[f\"{split}_labels\"]\n",
        "      self.orig_images = data[f\"{split}_orig\"]\n",
        "\n",
        "      self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      img = self.images[idx].astype(np.float32)\n",
        "      orig = self.orig_images[idx]\n",
        "      label = int(self.labels[idx])\n",
        "\n",
        "      # Add channel dimension: (1, H, W)\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "\n",
        "      if self.transform:\n",
        "          img = self.transform(img)\n",
        "\n",
        "      return {\"img\": img, \"label\": label, \"orig\": orig}"
      ],
      "metadata": {
        "id": "ZimRD9OG8gio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to visualize the scans\n",
        "def visualize_sample(sample):\n",
        "    plt.imshow(sample['img'], 'gray')\n",
        "    if sample['label'] == 1:\n",
        "        plt.title('Patient with inflamation')\n",
        "    else:\n",
        "        plt.title('Healthy patient')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vRRhYX-m8jnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import medmnist\n",
        "%pip install monai"
      ],
      "metadata": {
        "id": "dc8WT-td85GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import NormalizeIntensity\n",
        "\n",
        "data_transform = NormalizeIntensity(subtrahend=.5, divisor=.5)\n",
        "\n",
        "train_dataset = TeethMNIST(split=\"train\", transform=data_transform)\n",
        "val_dataset = TeethMNIST(split=\"val\", transform=data_transform)\n",
        "test_dataset = TeethMNIST(split=\"test\", transform=data_transform)"
      ],
      "metadata": {
        "id": "U9GRVPeh8nnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYes0xWe3o56"
      },
      "source": [
        "## Πειραματισμός με τον κώδικα και εξερεύνηση του dataset):\n",
        "\n",
        "Το train_dataset είναι ένα σύνολο από 4708 σαρώσεις, όπου κάθε σάρωση έχει μια ετικέτα (label), η οποία μπορεί να είναι 0 ή 1.\n",
        "Η ετικέτα 0 σημαίνει ότι ο ασθενής είναι υγιής, ενώ η ετικέτα 1 σημαίνει ότι ο ασθενής έχει πνευμονία.\n",
        "\n",
        "Αν πληκτρολογήσεις\n",
        "<kbd>visualize(train_dataset[k]['img'])</kbd>\n",
        "μπορείς να δεις την k‑οστή εικόνα.\n",
        "\n",
        "Αν πληκτρολογήσεις\n",
        "<kbd>print(train_dataset[k]['label'])</kbd>\n",
        "θα δεις την ετικέτα που αντιστοιχεί σε αυτή την εικόνα.\n",
        "\n",
        "Πειραματίσου με\n",
        "<kbd>visualize_sample(train_dataset[k])</kbd>\n",
        "για να εξερευνήσεις το dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRckFklx3o56"
      },
      "outputs": [],
      "source": [
        "sample = train_dataset[11]\n",
        "visualize(sample[\"img\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO7ro6ug3o56"
      },
      "source": [
        "Παρακάτω μπορείς να εμφανίσεις μια ακτινογραφία ενός τυχαίου ασθενούς. Για να μπορέσουμε αργότερα να ερμηνεύσουμε καλύτερα τις προβλέψεις του αλγορίθμου, είναι σημαντικό να γνωρίζουμε πόσες εικόνες στα δεδομένα προέρχονται από ασθενείς με απονευρώσεις και πόσες από ασθενείς χωρίς.\n",
        "\n",
        "Παρακάτω μπορείς να δεις πόσα δεδομένα ανήκουν στη μία και πόσα στην άλλη κατηγορία.\n",
        "\n",
        "**Ερώτηση**: Είναι το dataset ισορροπημένο; Ποιο ποσοστό των δεδομένων εκπαίδευσης αφορά ασθενείς με απονεύρωση;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEtLMVvw3o56"
      },
      "outputs": [],
      "source": [
        "# visualize a random sample\n",
        "index = np.random.choice(np.arange(len(train_dataset)))\n",
        "sample = train_dataset[index]\n",
        "visualize(sample[\"img\"][0])\n",
        "\n",
        "#Question: is this dataset inbalanced?\n",
        "counts = {0: 0, 1:0}\n",
        "for sample in train_dataset:\n",
        "    counts[sample['label'][0]] += 1\n",
        "print('Aanal label 0:', counts[0], 'Aantal label 1:', counts[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFKpnIj3o56"
      },
      "source": [
        "Τώρα θα δημιουργήσουμε το πραγματικό δίκτυο. Χωρίζουμε τα δεδομένα σε ένα σύνολο δοκιμής και ένα σύνολο επικύρωσης, ώστε αργότερα να μπορούμε να ελέγξουμε αν το μοντέλο υπερπροσαρμόζεται. Δημιουργούμε ένα μοντέλο με δύο στρώματα συνελικτικών φίλτρων με kernels 3x3. Πίσω από αυτά ακολουθεί ένα νευρωνικό δίκτυο και φροντίζουμε να υπάρχει μία μόνο έξοδος (απονεύρωση ή όχι). Αυτό το μοντέλο έχει υλοποιηθεί ως Net()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpjW25113o56"
      },
      "outputs": [],
      "source": [
        "import monai\n",
        "\"\"\"\n",
        "Δημιουργούμε το σύνολο επικύρωσης, ώστε να μπορούμε να δούμε πώς γενικεύει\n",
        "το μοντέλο κατά την εκπαίδευση. Το σύνολο επικύρωσης δεν χρησιμοποιείται\n",
        "για την προσαρμογή των βαρών του μοντέλου.\n",
        "\"\"\"\n",
        "\n",
        "val_dataset = TeethMNIST(split=\"val\", transform=data_transform)\n",
        "\n",
        "# dataloader που καλεί τα δεδομένα για την εκπαίδευση\n",
        "\n",
        "train_dataloader = monai.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = monai.data.DataLoader(val_dataset, batch_size = 32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bLlSVbH3o57"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 6: Κατασκευή δομής νευρωνικού δικτύου.\n",
        "\n",
        "\"\"\"\n",
        "Εδώ ορίζεται το πραγματικό μοντέλο. Αυτό το μοντέλο είναι ένα συνελικτικό\n",
        "νευρωνικό δίκτυο (CNN) που αποτελείται από 2 συνελικτικά επίπεδα και 2 πλήρως\n",
        "συνδεδεμένα επίπεδα.\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)             # Een convolutie met 1 input channel (de afbeelding), 32 output channels (32 verschillende kernels), 3x3 pixel kernel\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)            # Een tweede convolutie met 32 input channels (de 32 output channels van de vorige laag), 64 output channels (verschillende kernels), 3x3 pixel kernel\n",
        "        self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=1)                                       # De output laag met 1 output neuron (de voorspelling, tussen 0 (geen longontsteking) en 1( longontsteking) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        output = self.fc2(x)\n",
        "        return output\n",
        "\n",
        "net = Net()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVBatyT3o57"
      },
      "source": [
        "Πρέπει επίσης να καθορίσουμε ποια συνάρτηση απώλειας θα χρησιμοποιεί το δίκτυο κατά την εκπαίδευση. Χρησιμοποιούμε τη συνάρτηση binary cross-entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLuyJ6x_3o57"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 7: Το model θα είναι το νευρωνικό μας δίκτυο\n",
        "\n",
        "model = Net()\n",
        "model.cuda() # εδώ χρειάζεται η ρύθμιση GPU\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loss_function = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF9XCG_E3o57"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 8: εκπαίδευση νευρωνικού δικτύου\n",
        "\n",
        "from tqdm import tqdm\n",
        "# function to train the model\n",
        "\n",
        "def train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs, device='cuda', val_freq=1):\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # model in train modus\n",
        "        model.train()\n",
        "        steps = 0\n",
        "        epoch_loss = 0\n",
        "        # loop over de batches in training data\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            images = batch['img'].float().to(device)\n",
        "            labels = batch['label'].float().to(device)\n",
        "            labels = labels.unsqueeze(1)\n",
        "            # haal plaatjes door het model\n",
        "            output = model(images)\n",
        "            # bereken de loss tussen de targets en de outputs van het model\n",
        "            loss = loss_function(output, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            # back propagation, update de weights in het netwerk\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            steps += 1\n",
        "\n",
        "        train_loss.append(epoch_loss/steps)\n",
        "\n",
        "        # validation loop\n",
        "        if epoch % val_freq == 0:\n",
        "            steps = 0\n",
        "            val_epoch_loss = 0\n",
        "            model.eval()\n",
        "            for batch in val_dataloader:\n",
        "                images = batch['img'].float().to(device)\n",
        "                labels = batch['label'].float().to(device)\n",
        "                labels = labels.unsqueeze(1)\n",
        "                output = model(images)\n",
        "                loss = loss_function(output, labels)\n",
        "                val_epoch_loss += loss.item()\n",
        "                steps += 1\n",
        "            val_loss.append(val_epoch_loss/steps)\n",
        "\n",
        "    # plot the losses together\n",
        "    plt.plot(train_loss, label='train loss')\n",
        "    plt.plot(np.arange(0, epochs, val_freq), val_loss, label='val loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model, train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN5RUEDz3o57"
      },
      "source": [
        "Τώρα που έχουμε εισαγάγει το νευρωνικό δίκτυο, τη συνάρτηση απώλειας και τα δεδομένα, μπορούμε να προχωρήσουμε στην πραγματική εκπαίδευση του μοντέλου και να μάθουμε τα kernels που θα χρησιμοποιήσει για να διακρίνει υγιείς από μη υγιείς ασθενείς. Ο παρακάτω κώδικας δείχνει πώς η συνάρτηση απώλειας μειώνεται κατά την εκπαίδευση, τόσο στα δεδομένα εκπαίδευσης όσο και στα δεδομένα επικύρωσης.\n",
        "\n",
        "Ερώτηση: Αν κοιτάξεις τα διαγράμματα της συνάρτησης απώλειας στα δεδομένα εκπαίδευσης και στα δεδομένα επικύρωσης, πιστεύεις ότι το μοντέλο έχει υπερπροσαρμοστεί; Και τώρα που εκπαιδεύσαμε το μοντέλο για 100 epochs, θα μπορούσε αυτό να είχε γίνει και σε λιγότερα;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LImMggkT3o57"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 9: αποτελέσματα\n",
        "\n",
        "val_freq = 10\n",
        "\n",
        "# 100 iteraties trainen\n",
        "n_epochs = 50\n",
        "model, train_loss, val_loss = train_medmnist(model, train_dataloader,\n",
        "                                             val_dataloader, optimizer,\n",
        "                                             epochs=n_epochs, val_freq=val_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSsxx5gV3o58"
      },
      "source": [
        "Έχουμε δει παραπάνω τι μπορούν να αναγνωρίσουν συγκεκριμένα kernels μέσα σε μια εικόνα. Αλλά ποια kernels έχει βρει ο αλγόριθμός μας για να ταξινομεί ανάμεσα σε υγιείς και ασθενείς πνεύμονες; Παρακάτω βλέπουμε τα kernels του δεύτερου συνελικτικού επιπέδου. Επειδή το πρώτο επίπεδο έχει ήδη εφαρμόσει 16 συνελίξεις, υπάρχουν 16 διαφορετικά σύνολα kernels στο δεύτερο επίπεδο. Μπορείς να τα δεις όλα προσαρμόζοντας τη μεταβλητή <kbd>input_index</kbd>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqUrH8nI3o6Q"
      },
      "outputs": [],
      "source": [
        "# Ενότητα 10: τα φίλτρα που έμαθε στην πρώτη και δεύτερη στρώση\n",
        "\n",
        "input_index = 16\n",
        "fig, axs = plt.subplots(8,8, layout='constrained')\n",
        "for i in range(64):\n",
        "    kernel = model.conv2.weight[i,input_index,:,:].detach().cpu().numpy()\n",
        "    cur_ax = np.unravel_index(i, [8,8])\n",
        "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
        "    axs[cur_ax].axis('off')\n",
        "plt.suptitle(f'Geleerde kernels uit de tweede convolutional laag, input channel {input_index}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDDykKEZ3o6Q"
      },
      "source": [
        "Και εδώ βλέπουμε επίσης τα kernels από το πρώτο συνελικτικό επίπεδο."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_3dOIFB3o6R"
      },
      "outputs": [],
      "source": [
        "print(np.shape(model.conv1.weight))\n",
        "fig, axs = plt.subplots(4,8, layout='constrained')\n",
        "for i in range(32):\n",
        "    kernel = model.conv1.weight[i,0,:,:].detach().cpu().numpy()\n",
        "    cur_ax = np.unravel_index(i, [4,8])\n",
        "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
        "    axs[cur_ax].axis('off')\n",
        "plt.suptitle(f'Geleerde kernels uit de eerste convolutional laag')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUUfgnJF3o6R"
      },
      "source": [
        "## Performance assessment\n",
        "\n",
        "Τώρα που έχουμε εκπαιδεύσει το μοντέλο, θα εξετάσουμε σε ποιο βαθμό μπορεί να κάνει σωστές προβλέψεις. Πρώτα υπολογίζουμε τη recall και την precision του μοντέλου.\n",
        "\n",
        "Η **recall** μας δείχνει πόσα από τα θετικά δείγματα χάνονται από το μοντέλο (ψευδώς αρνητικά).\n",
        "\n",
        "Η **precision** μετρά πόσα από τα δείγματα που ταξινομούνται ως θετικά είναι πράγματι θετικά (ψευδώς θετικά).\n",
        "\n",
        "Το ποιο μέτρο είναι πιο σημαντικό εξαρτάται από το εκάστοτε πρόβλημα. Για παράδειγμα, στην ανίχνευση μιας εξαιρετικά σπάνιας μορφής καρκίνου, προτιμάμε υψηλή recall και αποδεχόμαστε χαμηλότερη precision. Είναι προτιμότερο να εντοπίζονται τα πραγματικά θετικά και να φιλτράρονται αργότερα τα ψευδώς θετικά σε περαιτέρω εξετάσεις, παρά να χάνονται εντελώς τα θετικά περιστατικά.\n",
        "\n",
        "Για τον υπολογισμό αυτών των μετρικών χρησιμοποιούμε το test dataset (και όχι το validation dataset).\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)\n",
        "\n",
        "Πριν υπολογίσουμε αυτές τις μετρικές, θα εξετάσουμε πρώτα μερικές από τις εξόδους του μοντέλου.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddpeEeNZ3o6R"
      },
      "outputs": [],
      "source": [
        "#Ενότητα 11: προβλέψεις σε αρχικές ατκίνες\n",
        "\n",
        "def validation_results_visualize(model, dataset):\n",
        "    index = np.random.randint(0, len(dataset))\n",
        "    sample = dataset[index]\n",
        "\n",
        "    image = sample['img']\n",
        "    label = sample['label']\n",
        "    original_img = sample['orig']\n",
        "\n",
        "    plt.imshow(sample['orig'], cmap='gray')\n",
        "    plt.yticks([]); plt.xticks([])\n",
        "\n",
        "    # convert to tensor\n",
        "    image_t = torch.tensor(image).float().to('cuda') # shape (1,28,28)\n",
        "\n",
        "    with torch.no_grad():\n",
        "         output = torch.sigmoid(model(image_t.unsqueeze(0))).item()\n",
        "         print(index)\n",
        "         plt.title(\n",
        "             f\"Πραγματική τιμή: {label},\"\n",
        "             f\"πιθανότητα απονεύρωσης :{output:.3f},\"\n",
        "             f\"πρόβλεψη CNN: {int(output >= 0.5)}\")\n",
        "         plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_results_visualize(model, test_dataset)"
      ],
      "metadata": {
        "id": "9IOQiOukbEAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PvUsCFH3o6R"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    validation_results_visualize(model, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTISi7aE3o6R"
      },
      "outputs": [],
      "source": [
        "#Ενότητα 12: Ανάλυση της απόδοσης του δικτύου\n",
        "\n",
        "# we compute precision and recall\n",
        "def get_precision_recall(model, dataloader):\n",
        "    model.eval()\n",
        "    TP, TN, FP, FN = 0, 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "         for batch in dataloader:\n",
        "             images = batch['img'].float().to('cuda') # (B,1,28,28)\n",
        "             labels = batch['label'].float().to('cuda') # (B,)\n",
        "             labels = labels.unsqueeze(1) # (B,1)\n",
        "             outputs = torch.sigmoid(model(images)) # (B,1)\n",
        "             preds = (outputs >= 0.5).float() # (B,1)\n",
        "             TP += ((preds == 1) & (labels == 1)).sum().item()\n",
        "             TN += ((preds == 0) & (labels == 0)).sum().item()\n",
        "             FP += ((preds == 1) & (labels == 0)).sum().item()\n",
        "             FN += ((preds == 0) & (labels == 1)).sum().item()\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "\n",
        "    return precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDuhQylk3o6R"
      },
      "outputs": [],
      "source": [
        "test_dataset = TeethMNIST(split=\"test\",transform=data_transform)\n",
        "test_loader = monai.data.DataLoader(test_dataset, batch_size = 32, shuffle=False)\n",
        "\n",
        "precision, recall = get_precision_recall(model, test_loader)\n",
        "print(f'De precision van het getrainde model is {precision:.2f}, de recall van het getrainde model is {recall:.2f}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgCnyfTk3o6S"
      },
      "source": [
        "**Ερώτηση**: Τι γνώμη έχεις για την precision και την recall του μοντέλου (λαμβάνοντας επίσης υπόψη πόσο ποσοστό των ασθενών (50%) στα δεδομένα έχει κάνει απονεύρωση);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO7AxRs93o6S"
      },
      "source": [
        "Παρακάτω μπορείς να δεις ένα λεγόμενο confusion matrix. Πόσες περιπτώσεις πνευμονίας έχουν περάσει απαρατήρητες; Και πόσο συχνά διαγιγνώσκεται ένας ασθενής λανθασμένα με πνευμονία; Τι εικόνα μας δίνει αυτό για το πόσο ισχυρό είναι το μοντέλο; Μπορείς επίσης να βρεις αν το μοντέλο αποδίδει καλά και στο validation dataset; Ο dataloader για το σύνολο επικύρωσης ονομάζεται <kbd>val_dataloader</kbd>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9fd8YXu3o6S"
      },
      "outputs": [],
      "source": [
        "#Ενότητα 13: κατασκευή confusion matrix όπου μπορούμε να δούμε πόσο καλά\n",
        "# λειτούργησε το δίκτυο\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model,dataloader):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using true and predicted labels.\n",
        "\n",
        "    :param y_true: List or array of true labels.\n",
        "    :param y_pred: List or array of predicted labels.\n",
        "    :param labels: List of label names (optional).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "\n",
        "    for data in dataloader:\n",
        "        images = data['img'].float().to('cuda')\n",
        "        labels = data['label'].cpu().numpy()\n",
        "        with torch.no_grad():\n",
        "            output = torch.sigmoid(model(images)).cpu().numpy().flatten()\n",
        "        pred_classes = (output >= 0.5).astype(int)\n",
        "        true_labels.extend(labels)\n",
        "        predicted_labels.extend(pred_classes)\n",
        "\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=[0,1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['χωρίς απονεύρωση', 'με απονεύρωση'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Τι βλέπει το μοντέλο στην κάθε ακτινογραφία;\n",
        "\n",
        "Τα νευρωνικά δίκτυα μπορούν να κάνουν πολύ καλές προβλέψεις, αλλά συχνά δεν ξέρουμε πώς έφτασαν σε αυτές.\n",
        "Το Grad‑CAM μας δείχνει σε ποια σημεία της εικόνας βασίστηκε το μοντέλο για να πάρει την απόφασή του.\n",
        "\n",
        "Είναι σαν να βάζουμε έναν θερμικό χάρτη πάνω στην ακτινογραφία.\n",
        "\n",
        "Κόκκινο → το μοντέλο έδωσε μεγάλη σημασία\n",
        "\n",
        "Κίτρινο/πράσινο → μέτρια σημασία\n",
        "\n",
        "Μπλε → μικρή ή καθόλου σημασία\n"
      ],
      "metadata": {
        "id": "6IkcmZg4b2lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        # Forward hook → save activations\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations = output.detach()\n",
        "\n",
        "        # Backward hook → save gradients\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients = grad_output[0].detach()\n",
        "\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def generate(self, input_tensor):\n",
        "        # Forward pass\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Backward pass for predicted class\n",
        "        self.model.zero_grad()\n",
        "        output.backward()\n",
        "\n",
        "        # Global average pooling of gradients\n",
        "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
        "\n",
        "        # Weighted sum of activations\n",
        "        cam = (weights * self.activations).sum(dim=1).squeeze()\n",
        "\n",
        "        # Normalize CAM\n",
        "        cam = cam.cpu().numpy()\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "        return cam"
      ],
      "metadata": {
        "id": "PnptMc1v99XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_gradcam(model, dataset, index, device='cuda'):\n",
        "    sample = dataset[index]\n",
        "\n",
        "    small_img = sample['img']              # (1,28,28)\n",
        "    orig_img = sample['orig']              # original image\n",
        "    label = sample['label']\n",
        "\n",
        "    # Prepare tensor for model\n",
        "    input_tensor = torch.tensor(small_img).unsqueeze(0).float().to(device)\n",
        "\n",
        "    # Build Grad-CAM object\n",
        "    gradcam = GradCAM(model, model.conv2)\n",
        "\n",
        "    # Generate CAM\n",
        "    cam = gradcam.generate(input_tensor)\n",
        "\n",
        "    # Resize CAM to original image size\n",
        "    cam_resized = cv2.resize(cam, (orig_img.shape[1], orig_img.shape[0]))\n",
        "\n",
        "    # Convert CAM to heatmap\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Overlay heatmap on original image\n",
        "    overlay = 0.4 * heatmap + 0.6 * np.stack([orig_img]*3, axis=-1)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(orig_img, cmap='gray')\n",
        "    plt.title(f\"Original image (label={label})\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(overlay.astype(np.uint8))\n",
        "    plt.title(\"Grad-CAM heatmap\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "H8OWmiD9bxu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}